{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 概述\n",
    "\n",
    "Transformer是一种神经网络结构，由Vaswani等人在2017年的论文“Attention Is All You Need”中提出，用于处理机器翻译、语言建模和文本生成等自然语言处理任务。\n",
    "\n",
    "与带有Attention机制的Seq2Seq模型所不同的是，Transformer模型是一个纯基于注意力机制的架构，不包含任何循环神经网络（Recurrent Neural Network， RNN）或卷积神经网络（Convolutional Neural Network，CNN）。其中，在处理输入序列上，Transformer引入了自注意力机制（self-attention mechanism）。使其能够衡量输入序列中不同部分的重要性，并有选择性地关注最相关的信息，从而能够更有效地捕捉数据中的长期依赖关系。\n",
    "\n",
    "Transformer的另一个关键特征是它在对输入序列进行编码时， 在原有Embedding上添加了位置编码（Positional Encoding），弥补了自注意力机制中缺失的位置信息，使模型在训练中可以学习这部分信息，区分具有相同数字序列单不同位置的单词。\n",
    "\n",
    "总体而言，与NLP领域中的前序模型（LSTM、GRU、Seq2Seq等）相比，Transformer具有几个优点：\n",
    "1. 更容易并行化，训练更加高效；\n",
    "2. 运算中不会改变输入数据的shape，大大减少了搭建模型中统一tensor shape的工作；\n",
    "3. 在处理长序列的任务中表现优秀，可以快速捕捉长距离中的关联信息。\n",
    "\n",
    "上述优势使其成为各种自然语言处理任务的热门选择，并在其架构基础上衍生出了BERT、GPT等模型。\n",
    "\n",
    "## 数据准备\n",
    "\n",
    "我们本次使用的数据集为**Multi30K数据集**，它是一个大规模的图像-文本数据集，包含30K+图片，每张图片对应两类不同的文本描述：\n",
    "- 英语描述，及对应的德语翻译；\n",
    "- 五个独立的、非翻译而来的英语和德语描述，描述中包含的细节并不相同；\n",
    "\n",
    "因其收集的不同语言对于图片的描述相互独立，所以训练出的模型可以更好地适用于有噪声的多模态内容。\n",
    "\n",
    "![avatar](./assets/Multi30K.png)\n",
    "> 图片来源：Elliott, D., Frank, S., Sima’an, K., & Specia, L. (2016). Multi30K: Multilingual English-German Image Descriptions. CoRR, 1605.00459.\n",
    "\n",
    "首先，我们需要下载如下依赖：\n",
    "\n",
    "- 分词工具：`pip install spacy`\n",
    "- 德语/英语分词器：`python -m spacy download de_core_news_sm`，`python -m spacy download en_core_web_sm`\n",
    "\n",
    "### 数据下载模块\n",
    "\n",
    "使用`download`进行数据下载，并将`tar.gz`文件解压到指定文件夹。\n",
    "\n",
    "下载好的数据集目录结构如下：\n",
    "\n",
    "```text\n",
    "home_path/.mindspore_examples\n",
    "├─test\n",
    "│      test2016.de\n",
    "│      test2016.en\n",
    "│      test2016.fr\n",
    "│\n",
    "├─train\n",
    "│      train.de\n",
    "│      train.en\n",
    "│\n",
    "└─valid\n",
    "        val.de\n",
    "        val.en\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replace is False and data exists, so doing nothing. Use replace=True to re-download the data.\n",
      "Replace is False and data exists, so doing nothing. Use replace=True to re-download the data.\n",
      "Replace is False and data exists, so doing nothing. Use replace=True to re-download the data.\n"
     ]
    }
   ],
   "source": [
    "from download import download\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# 训练、验证、测试数据集下载地址\n",
    "urls = {\n",
    "    'train': 'http://www.quest.dcs.shef.ac.uk/wmt16_files_mmt/training.tar.gz',\n",
    "    'valid': 'http://www.quest.dcs.shef.ac.uk/wmt16_files_mmt/validation.tar.gz',\n",
    "    'test': 'http://www.quest.dcs.shef.ac.uk/wmt17_files_mmt/mmt_task1_test2016.tar.gz'\n",
    "}\n",
    "\n",
    "# 指定保存路径为 `home_path/.mindspore_examples`\n",
    "cache_dir = Path.home() / '.mindspore_examples'\n",
    "\n",
    "train_path = download(urls['train'], os.path.join(cache_dir, 'train'), kind='tar.gz')\n",
    "valid_path = download(urls['valid'], os.path.join(cache_dir, 'valid'), kind='tar.gz')\n",
    "test_path = download(urls['test'], os.path.join(cache_dir, 'test'), kind='tar.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据预处理\n",
    "\n",
    "在使用数据进行模型训练等操作时，我们需要对数据进行预处理，流程如下：\n",
    "\n",
    "1. 加载数据集，目前数据为句子形式的文本，需要进行分词，即将句子拆解为单独的词元（token，可以为字符或者单词）；\n",
    "    - 分词可以使用`spaCy`创建分词器（tokenizer）：`de_core_news_sm`，`en_core_web_sm`，需要手动下载；\n",
    "    - 分词后，去除多余的空格，统一大小写等；\n",
    "2. 将每个词元映射到从0开始的数字索引中（为节约存储空间，可过滤掉词频低的词元），词元和数字索引所构成的集合叫做词典（vocabulary）；\n",
    "3. 添加特殊占位符，标明序列的起始与结束，统一序列长度，并创建数据迭代器；\n",
    "\n",
    "#### 数据加载器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from functools import partial\n",
    "\n",
    "class Multi30K():\n",
    "    \"\"\"Multi30K数据集加载器\n",
    "\n",
    "    加载Multi30K数据集并处理为一个Python迭代对象。\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, path):\n",
    "        self.data = self._load(path)\n",
    "\n",
    "    def _load(self, path):\n",
    "        def tokenize(text, spacy_lang):\n",
    "            # 去除多余空格，统一大小写\n",
    "            text = text.rstrip()\n",
    "            return [tok.text.lower() for tok in spacy_lang.tokenizer(text)]\n",
    "\n",
    "        # 加载英、德语分词器\n",
    "        tokenize_de = partial(tokenize, spacy_lang=spacy.load('de_core_news_sm'))\n",
    "        tokenize_en = partial(tokenize, spacy_lang=spacy.load('en_core_web_sm'))\n",
    "\n",
    "        # 读取Multi30K数据，并进行分词\n",
    "        members = {i.split('.')[-1]: i for i in os.listdir(path)}\n",
    "        de_path = os.path.join(path, members['de'])\n",
    "        en_path = os.path.join(path, members['en'])\n",
    "        with open(de_path, 'r') as de_file:\n",
    "            de = de_file.readlines()[:-1]\n",
    "            de = [tokenize_de(i) for i in de]\n",
    "        with open(en_path, 'r') as en_file:\n",
    "            en = en_file.readlines()[:-1]\n",
    "            en = [tokenize_en(i) for i in en]\n",
    "\n",
    "        return list(zip(de, en))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, valid_dataset, test_dataset = Multi30K(train_path), Multi30K(valid_path), Multi30K(test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对解压和分词结果进行测试，打印测试数据集第一组英德语文本，可以看到每一个单词和标点符号已经被单独分离出来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de = ['ein', 'mann', 'mit', 'einem', 'orangefarbenen', 'hut', ',', 'der', 'etwas', 'anstarrt', '.']\n",
      "en = ['a', 'man', 'in', 'an', 'orange', 'hat', 'starring', 'at', 'something', '.']\n"
     ]
    }
   ],
   "source": [
    "for de, en in test_dataset:\n",
    "    print(f'de = {de}')\n",
    "    print(f'en = {en}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 词典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    \"\"\"通过词频字典，构建词典\"\"\"\n",
    "\n",
    "    special_tokens = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
    "\n",
    "    def __init__(self, word_count_dict, min_freq=1):\n",
    "        self.word2idx = {}\n",
    "        for idx, tok in enumerate(self.special_tokens):\n",
    "            self.word2idx[tok] = idx\n",
    "\n",
    "        # 过滤低词频的词元\n",
    "        filted_dict = {\n",
    "            w: c\n",
    "            for w, c in word_count_dict.items() if c >= min_freq\n",
    "        }\n",
    "        for w, _ in filted_dict.items():\n",
    "            self.word2idx[w] = len(self.word2idx)\n",
    "\n",
    "        self.idx2word = {idx: word for word, idx in self.word2idx.items()}\n",
    "\n",
    "        self.bos_idx = self.word2idx['<bos>']  # 特殊占位符：序列开始\n",
    "        self.eos_idx = self.word2idx['<eos>']  # 特殊占位符：序列结束\n",
    "        self.pad_idx = self.word2idx['<pad>']  # 特殊占位符：补充字符\n",
    "        self.unk_idx = self.word2idx['<unk>']  # 特殊占位符：低词频词元或未曾出现的词元\n",
    "\n",
    "    def _word2idx(self, word):\n",
    "        \"\"\"单词映射至数字索引\"\"\"\n",
    "        if word not in self.word2idx:\n",
    "            return self.unk_idx\n",
    "        return self.word2idx[word]\n",
    "\n",
    "    def _idx2word(self, idx):\n",
    "        \"\"\"数字索引映射至单词\"\"\"\n",
    "        if idx not in self.idx2word:\n",
    "            raise ValueError('input index is not in vocabulary.')\n",
    "        return self.idx2word[idx]\n",
    "\n",
    "    def encode(self, word_or_list):\n",
    "        \"\"\"将单个单词或单词数组映射至单个数字索引或数字索引数组\"\"\"\n",
    "        if isinstance(word_or_list, list):\n",
    "            return [self._word2idx(i) for i in word_or_list]\n",
    "        return self._word2idx(word_or_list)\n",
    "\n",
    "    def decode(self, idx_or_list):\n",
    "        \"\"\"将单个数字索引或数字索引数组映射至单个单词或单词数组\"\"\"\n",
    "        if isinstance(idx_or_list, list):\n",
    "            return [self._idx2word(i) for i in idx_or_list]\n",
    "        return self._idx2word(idx_or_list)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.word2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过自定义词频字典进行测试，我们可以看到词典已去除词频少于2的词元c，并加入了默认的四个特殊占位符，故词典整体长度为：4 - 1 + 4 = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count = {'a':20, 'b':10, 'c':1, 'd':2}\n",
    "\n",
    "vocab = Vocab(word_count, min_freq=2)\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用`collections`中的`Counter`和`OrderedDict`统计英/德语每个单词在整体文本中出现的频率。构建词频字典，然后再将词频字典转为词典。\n",
    "\n",
    "在分配数字索引时有一个小技巧：常用的词元对应数值较小的索引，这样可以节约空间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, OrderedDict\n",
    "\n",
    "def build_vocab(dataset):\n",
    "    de_words, en_words = [], []\n",
    "    for de, en in dataset:\n",
    "        de_words.extend(de)\n",
    "        en_words.extend(en)\n",
    "\n",
    "    de_count_dict = OrderedDict(sorted(Counter(de_words).items(), key=lambda t: t[1], reverse=True))\n",
    "    en_count_dict = OrderedDict(sorted(Counter(en_words).items(), key=lambda t: t[1], reverse=True))\n",
    "\n",
    "    return Vocab(de_count_dict, min_freq=2), Vocab(en_count_dict, min_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in de vocabulary: 7853\n"
     ]
    }
   ],
   "source": [
    "de_vocab, en_vocab = build_vocab(train_dataset)\n",
    "print('Unique tokens in de vocabulary:', len(de_vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据迭代器\n",
    "\n",
    "数据预处理的最后一步是创建数据迭代器，我们在进一步处理数据（包括批处理，添加起始和终止符号，统一序列长度）后，将数据以张量的形式返回。\n",
    "\n",
    "创建数据迭代器需要如下参数：\n",
    "\n",
    "- `dataset`：分词后的数据集\n",
    "- `de_vocab`：德语词典\n",
    "- `en_vocab`：英语词典\n",
    "- `batch_size`：批量大小，即一个batch中包含多少个序列\n",
    "- `max_len`：序列最大长度，为最长有效文本长度 + 2（序列开始、序列结束占位符），如不满则补齐，如超过则丢弃\n",
    "- `drop_remainder`：是否在最后一个batch未满时，丢弃该batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore\n",
    "\n",
    "class Iterator():\n",
    "    \"\"\"创建数据迭代器\"\"\"\n",
    "    def __init__(self, dataset, de_vocab, en_vocab, batch_size, max_len=32, drop_reminder=False):\n",
    "        self.dataset = dataset\n",
    "        self.de_vocab = de_vocab\n",
    "        self.en_vocab = en_vocab\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.max_len = max_len\n",
    "        self.drop_reminder = drop_reminder\n",
    "\n",
    "        length = len(self.dataset) // batch_size\n",
    "        self.len = length if drop_reminder else length + 1  # 批量数量\n",
    "\n",
    "    def __call__(self):\n",
    "        def pad(idx_list, vocab, max_len):\n",
    "            \"\"\"统一序列长度，并记录有效长度\"\"\"\n",
    "            idx_pad_list, idx_len = [], []\n",
    "            # 当前序列度超过最大长度时，将超出的部分丢弃；当前序列长度小于最大长度时，用占位符补齐\n",
    "            for i in idx_list:\n",
    "                if len(i) > max_len - 2:\n",
    "                    idx_pad_list.append(\n",
    "                        [vocab.bos_idx] + i[:max_len-2] + [vocab.eos_idx]\n",
    "                    )\n",
    "                    idx_len.append(max_len)\n",
    "                else:\n",
    "                    idx_pad_list.append(\n",
    "                        [vocab.bos_idx] + i + [vocab.eos_idx] + [vocab.pad_idx] * (max_len - len(i) - 2)\n",
    "                    )\n",
    "                    idx_len.append(len(i) + 2)\n",
    "            return idx_pad_list, idx_len\n",
    "\n",
    "        def sort_by_length(src, trg):\n",
    "            \"\"\"对德/英语的字段长度进行排序\"\"\"\n",
    "            data = zip(src, trg)\n",
    "            data = sorted(data, key=lambda t: len(t[0]), reverse=True)\n",
    "            return zip(*list(data))\n",
    "\n",
    "        def encode_and_pad(batch_data, max_len):\n",
    "            \"\"\"将批量中的文本数据转换为数字索引，并统一每个序列的长度\"\"\"\n",
    "            # 将当前批量数据中的词元转化为索引\n",
    "            src_data, trg_data = zip(*batch_data)\n",
    "            src_idx = [self.de_vocab.encode(i) for i in src_data]\n",
    "            trg_idx = [self.en_vocab.encode(i) for i in trg_data]\n",
    "\n",
    "            # 统一序列长度\n",
    "            src_idx, trg_idx = sort_by_length(src_idx, trg_idx)\n",
    "            src_idx_pad, src_len = pad(src_idx, de_vocab, max_len)\n",
    "            trg_idx_pad, _ = pad(trg_idx, en_vocab, max_len)\n",
    "\n",
    "            return src_idx_pad, src_len, trg_idx_pad\n",
    "\n",
    "        for i in range(self.len):\n",
    "            # 获取当前批量的数据\n",
    "            if i == self.len - 1 and not self.drop_reminder:\n",
    "                batch_data = self.dataset[i * self.batch_size:]\n",
    "            else:\n",
    "                batch_data = self.dataset[i * self.batch_size: (i+1) * self.batch_size]\n",
    "\n",
    "            src_idx, src_len, trg_idx = encode_and_pad(batch_data, self.max_len)\n",
    "            # 将序列数据转换为tensor\n",
    "            yield mindspore.Tensor(src_idx, mindspore.int32), \\\n",
    "                mindspore.Tensor(src_len, mindspore.int32), \\\n",
    "                mindspore.Tensor(trg_idx, mindspore.int32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = Iterator(train_dataset, de_vocab, en_vocab, batch_size=128, max_len=32, drop_reminder=True)\n",
    "valid_iterator = Iterator(valid_dataset, de_vocab, en_vocab, batch_size=128, max_len=32, drop_reminder=False)\n",
    "test_iterator = Iterator(test_dataset, de_vocab, en_vocab, batch_size=128, max_len=32, drop_reminder=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型解析\n",
    "\n",
    "### Transformer 架构\n",
    "\n",
    "![avatar](./assets/transformer.png)\n",
    "\n",
    "> 图片来源：Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need, 2017.\n",
    "\n",
    "与Seq2Seq类似，Transformer模型由编码器（Encoder）与解码器（Decoder）构成。编码器将源序列embedding中的信息进行学习、整合，并处理为一个抽象的连续表示，随后将其传入解码器。解码器结合编码器输出与先前生成的单词，逐步生成输出序列。\n",
    "\n",
    "训练过程中，Transformer通过比较生成序列与真实目标序列的差距来更新网络参数，整体流程如下：\n",
    "\n",
    "1. 嵌入：将输入序列映射至高维向量空间，即把每一个词转化为一个向量。\n",
    "2. 位置编码：在内容编码的基础上添加位置信息。\n",
    "3. 编码：将带有位置信息的输入序列放入编码器中，通过自注意力、前馈神经网络等网络层学习输入序列中的信息，输出上下文向量。\n",
    "4. 解码：每次解码器通过编码器输出的上下文向量和目前已生成的序列生成下一个单词，并更新当前序列，直到生成完整的句子。\n",
    "5. 损失计算与网络更新：模型计算生成序列与目标序列的偏差，并通过反向传播计算梯度，更新网络参数。\n",
    "\n",
    "### 位置编码（Positional Encoding）\n",
    "\n",
    "Transformer模型不包含CNN或者RNN，所以无法在模型中记录时序信息，这样会导致模型无法识别由顺序改变而产生的句子含义的改变，如“我爱我的小猫”和“我的小猫爱我”。\n",
    "\n",
    "为了弥补这个缺陷，我们选择在输入数据中额外添加表示位置信息的位置编码，位置编码的计算方式如下：\n",
    "\n",
    "![avatar](./assets/transformer_word_embedding.png)\n",
    "\n",
    "如图，假设我们对$\\text{<bos> Hello world ! <eos>}$进行编码，最终生成一个5x4的word embedding。其中每一行表示一个词元的向量，列数表示嵌入的维度。\n",
    "\n",
    "对于索引为[pos, 2i]（所在列为偶数列）的元素，位置编码的计算方式如下：\n",
    "\n",
    "$$PE_{(pos,2i)} = \\sin\\Bigg(\\frac{pos}{10000^{2i/d_{\\text{model}}}}\\Bigg)$$\n",
    "\n",
    "对于索引为[pos, 2i+1]（所在列为奇数列）的元素，位置编码的计算方式如下：\n",
    "\n",
    "$$PE_{(pos,2i+1)} = \\cos\\Bigg(\\frac{pos}{10000^{2i/d_{\\text{model}}}}\\Bigg)$$\n",
    "\n",
    "这样可以保证每一个位置的词元对应的位置编码都有所不同，位置编码另一个好处是，由于使用了$\\sin$和$\\cos$函数，它可以表示词元之间的相对信息，即位置编码记录的是两个词之间的相对距离，从而使得它们之间的逻辑关系不会被这组词在序列中的整体位置影响。如：\n",
    "\n",
    "- “我不喜欢吃榴莲，因为它太臭了。”\n",
    "- “妈妈今天买了榴莲，可惜我不喜欢吃榴莲。”\n",
    "\n",
    "“我不喜欢吃榴莲”这个片段分别出现在了两个句子的句首和句尾，但均表示了“我”对“榴莲”的负面情绪。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore.ops as ops\n",
    "import mindspore.nn as nn\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Cell):\n",
    "    \"\"\"位置编码\"\"\"\n",
    "\n",
    "    def __init__(self, embed_dim, dropout=0.1, max_len=100):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=1 - dropout)\n",
    "\n",
    "        # 位置信息\n",
    "        # shape = [batch size = 1, max len, embed dim]\n",
    "        self.pos = ops.fill(compute_dtype, (1, max_len, embed_dim), 0)\n",
    "        angle = ops.arange(end=max_len, dtype=compute_dtype).reshape(\n",
    "            -1, 1) / ops.pow(\n",
    "                10000,\n",
    "                ops.arange(end=embed_dim, step=2, dtype=compute_dtype) /\n",
    "                embed_dim)\n",
    "        self.pos[:, :, 0::2] = ops.sin(angle)\n",
    "        self.pos[:, :, 1::2] = ops.cos(angle)\n",
    "\n",
    "    def construct(self, x):\n",
    "        # 将位置编码截取至x同等大小\n",
    "        # shape = [batch size = 1, seq len, embed dim]\n",
    "        x = x + self.pos[:, :x.shape[1], :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多头注意力（Multi-Head Attention）\n",
    "\n",
    "![avatar](./assets/transformer_multihead_attention.png)\n",
    "\n",
    "> 图片来源：Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need, 2017.\n",
    "\n",
    "#### 自注意力 (Self-Attention)\n",
    "\n",
    "相比注意力机制探究句子与句子之间的对应关系，自注意力关注一个句子中每个单词对于周边单词的重要性。它可以有效地识别句子中的代词指代，如在'`The animal` didn't cross the street because `it` was too tired'这句话中，'it'指代句中的'The animal'，所以自注意力会赋予'The'、'animal'更高的注意力分值。\n",
    "\n",
    "![avatar](./assets/transformer_self_attention.png)\n",
    "\n",
    "> 图片来源： [The Illustrated Transformer](http://jalammar.github.io/illustrated-transformer/) by Jay Alammer\n",
    "\n",
    "#### 多头注意力\n",
    "#### 带掩码的多头注意力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore.ops as ops\n",
    "\n",
    "\n",
    "def get_attn_pad_mask(seq_q, seq_k, pad_idx, broadcast=False):\n",
    "    \"\"\"注意力掩码：识别序列中的<pad>占位符\n",
    "\n",
    "    Args:\n",
    "        seq_q (Tensor): query序列，shape = [batch size, query len]\n",
    "        seq_k (Tensor): key序列，shape = [batch size, key len]\n",
    "        pad_idx (Tensor): key序列<pad>占位符对应的数字索引\n",
    "        broadcast (bool): 是否需要广播机制。默认：False\n",
    "            如True，返回shape = [batch size, query len, key len]；如False，返回shape = [batch size, key len]\n",
    "    \"\"\"\n",
    "    batch_size, len_q = seq_q.shape\n",
    "    batch_size, len_k = seq_k.shape\n",
    "\n",
    "    # 如果序列中元素对应<pad>占位符，则该位置在mask中对应元素为True\n",
    "    # shape = []\n",
    "    pad_attn_mask = ops.equal(seq_k, pad_idx)\n",
    "\n",
    "    if broadcast:\n",
    "        # 增加额外的维度\n",
    "        # shape = [batch size, 1, key len]\n",
    "        pad_attn_mask = pad_attn_mask.expand_dims(1)\n",
    "        # 将掩码广播到[batch size, query len, key len]\n",
    "        pad_attn_mask = ops.broadcast_to(pad_attn_mask,\n",
    "                                         (batch_size, len_q, len_k))\n",
    "\n",
    "    return pad_attn_mask\n",
    "\n",
    "\n",
    "def get_attn_subsequent_mask(seq_q, seq_k):\n",
    "    \"\"\"生成时间掩码，使decoder在第t时刻只能看到序列的前t-1个元素\n",
    "    \n",
    "    Args:\n",
    "        seq_q (Tensor): query序列，shape = [batch size, query len]\n",
    "        seq_k (Tensor): key序列，shape = [batch size, key len]\n",
    "        pad_idx (Tensor): key序列<pad>占位符对应的数字索引\n",
    "    \"\"\"\n",
    "    _, len_q = seq_q.shape\n",
    "    _, len_k = seq_k.shape\n",
    "    # 生成三角矩阵\n",
    "    # shape = [query len, key len]\n",
    "    ones = ops.ones((len_q, len_k), mindspore.float32)\n",
    "    subsequent_mask = ones.triu(diagonal=1)\n",
    "    # 在第0维增加额外维度\n",
    "    # shape = [1, query len, key len]\n",
    "    subsequent_mask = subsequent_mask.expand_dims(0)\n",
    "    return subsequent_mask\n",
    "\n",
    "\n",
    "def get_enc_dec_mask(src, trg, src_pad_idx, trg_pad_idx):\n",
    "    \"\"\"获取encoder与decoder中的掩码\"\"\"\n",
    "    # encoder 自注意力<pad>占位符掩码\n",
    "    # shape = [batch size, src len]\n",
    "    enc_self_attn_mask = get_attn_pad_mask(src, src, src_pad_idx)\n",
    "\n",
    "    # decoder 带有时间限制的自注意力掩码\n",
    "    # 分别计算<pad>占位符掩码与时间掩码，并合并\n",
    "    # shape = [batch size, trg len, trg len]\n",
    "    dec_self_attn_pad_mask = get_attn_pad_mask(trg,\n",
    "                                               trg,\n",
    "                                               trg_pad_idx,\n",
    "                                               broadcast=True)\n",
    "    dec_self_attn_subsequent_pad_mask = get_attn_subsequent_mask(trg, trg)\n",
    "    dec_self_attn_mask = dec_self_attn_pad_mask + dec_self_attn_subsequent_pad_mask\n",
    "    dec_self_attn_mask = ops.gt((dec_self_attn_mask), 0)\n",
    "\n",
    "    # decoder 注意力<pad>占位符掩码\n",
    "    # shape = [batch size, src len]\n",
    "    dec_enc_attn_mask = get_attn_pad_mask(trg, src, src_pad_idx)\n",
    "\n",
    "    return enc_self_attn_mask, dec_self_attn_mask, dec_enc_attn_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerNetwork(nn.Cell):\n",
    "\n",
    "    def __init__(self, d_model, nhead, num_encoder_layers, num_decoder_layers,\n",
    "                 dim_feedforward, max_len, src_vocab_size, trg_vocab_size):\n",
    "        super().__init__()\n",
    "\n",
    "        # 多头注意力头的数量\n",
    "        self.nhead = nhead\n",
    "        # 位置掩码\n",
    "        self.positional_encoding = PositionalEncoding(d_model,\n",
    "                                                      max_len=max_len + 1)\n",
    "        # 缩放比例\n",
    "        self.content_scale = ops.sqrt(\n",
    "            mindspore.Tensor([d_model], mindspore.float32))\n",
    "        # 源序列embedding\n",
    "        self.src_content_emb = nn.Embedding(src_vocab_size, d_model)\n",
    "        # 目标序列embedding\n",
    "        self.trg_content_emb = nn.Embedding(trg_vocab_size, d_model)\n",
    "        # transformer层\n",
    "        self.transformer = nn.Transformer(d_model,\n",
    "                                          nhead,\n",
    "                                          num_encoder_layers,\n",
    "                                          num_decoder_layers,\n",
    "                                          dim_feedforward,\n",
    "                                          batch_first=True)\n",
    "        # 全连接层\n",
    "        self.projection = nn.Dense(d_model, trg_vocab_size, has_bias=False)\n",
    "\n",
    "    def construct(self, src, trg, src_pad_idx, trg_pad_idx):\n",
    "        # 计算源序列与目标序列的embedding，并加入位置编码\n",
    "        # 为平衡原embedding和位置编码的数值，将原embedding以适当比例放大\n",
    "        # src shape = [batch size, src len, model dim]\n",
    "        # trg shape = [batch size, trg len, model dim]\n",
    "        src_emb = self.positional_encoding(\n",
    "            self.src_content_emb(src) * self.content_scale)\n",
    "        trg_emb = self.positional_encoding(\n",
    "            self.trg_content_emb(trg) * self.content_scale)\n",
    "\n",
    "        # encoder与decoder中的掩码\n",
    "        # 注意将dec_self_attn_mask的shape变为[batch size * head num, trg len, trg len]\n",
    "        enc_self_attn_mask, dec_self_attn_mask, dec_enc_attn_mask = get_enc_dec_mask(\n",
    "            src, trg, src_pad_idx, trg_pad_idx)\n",
    "        dec_self_attn_mask = ops.tile(dec_self_attn_mask, (self.nhead, 1, 1))\n",
    "\n",
    "        # transformer输出\n",
    "        output = self.transformer(src_emb,\n",
    "                                  trg_emb,\n",
    "                                  src_key_padding_mask=enc_self_attn_mask,\n",
    "                                  memory_key_padding_mask=dec_enc_attn_mask,\n",
    "                                  tgt_mask=dec_self_attn_mask)\n",
    "        \n",
    "        # logits计算\n",
    "        # shape = [batch size, trg len, trg vocab size]\n",
    "        dec_logits = self.projection(output)\n",
    "\n",
    "        # shape = [batch size * trg len, trg vocab size]\n",
    "        dec_logits = dec_logits.view((-1, dec_logits.shape[-1]))\n",
    "\n",
    "        return dec_logits.astype(compute_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 512  # Embedding层维度\n",
    "n_head = 8  # 多头感知机中头的数量\n",
    "n_layer = 6  # 编码器和解码器的层数\n",
    "d_ff = 2048  # 前馈神经网络维度\n",
    "max_len = 32  # 序列最大长度\n",
    "\n",
    "compute_dtype = mindspore.float32\n",
    "\n",
    "positional_encoding = PositionalEncoding(d_model, max_len=max_len + 1)  # 位置掩码\n",
    "src_content_emb = nn.Embedding(len(de_vocab), d_model)  # 源序列embedding\n",
    "trg_content_emb = nn.Embedding(len(en_vocab), d_model)  # 目标序列embedding\n",
    "src_pad_idx = de_vocab.pad_idx  # 源序列中<pad>占位符索引\n",
    "trg_pad_idx = en_vocab.pad_idx  # 目标序列中<pad>占位符索引\n",
    "src_vocab_size = len(de_vocab)\n",
    "trg_vocab_size = len(en_vocab)\n",
    "\n",
    "model = TransformerNetwork(d_model, n_head, n_layer, n_layer, d_ff, max_len,\n",
    "                           src_vocab_size, trg_vocab_size)\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=trg_pad_idx)\n",
    "opt = nn.Adam(model.trainable_params(), learning_rate=0.0001)\n",
    "\n",
    "\n",
    "def forward_fn(src, trg, src_pad_idx, trg_pad_idx):\n",
    "    \"\"\"前向网络\"\"\"\n",
    "    output = model(src, trg, src_pad_idx, trg_pad_idx)\n",
    "    # print(output.shape)\n",
    "    # print(trg[:, 1:].view(-1).shape)\n",
    "    loss = loss_fn(output, trg.view(-1))\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "# 反向传播计算梯度\n",
    "grad_fn = mindspore.value_and_grad(forward_fn, None, opt.parameters)\n",
    "\n",
    "\n",
    "def train_step(src, trg, src_pad_idx, trg_pad_idx):\n",
    "    \"\"\"单步训练\"\"\"\n",
    "    # 计算损失与梯度\n",
    "    loss, grads = grad_fn(src, trg, src_pad_idx, trg_pad_idx)\n",
    "    # 更新网络权重\n",
    "    opt(grads)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(iterator, epoch=0):\n",
    "    \"\"\"模型训练\"\"\"\n",
    "    model.set_train(True)\n",
    "    num_batches = len(iterator)\n",
    "    total_loss = 0  # 所有batch训练loss的累加\n",
    "    total_steps = 0  # 训练步数\n",
    "\n",
    "    with tqdm(total=num_batches) as t:\n",
    "        t.set_description(f'Epoch: {epoch}')\n",
    "        for src, src_len, trg in iterator():\n",
    "            # 计算当前batch数据的loss\n",
    "            loss = train_step(src, trg, src_pad_idx, trg_pad_idx)\n",
    "            total_loss += loss.asnumpy()\n",
    "            total_steps += 1\n",
    "            # 当前的平均loss\n",
    "            curr_loss = total_loss / total_steps\n",
    "            t.set_postfix({'loss': f'{curr_loss:.2f}'})\n",
    "            t.update(1)\n",
    "\n",
    "    return total_loss / total_steps\n",
    "\n",
    "\n",
    "def evaluate(iterator):\n",
    "    \"\"\"模型验证\"\"\"\n",
    "    model.set_train(False)\n",
    "    num_batches = len(iterator)\n",
    "    total_loss = 0 # 所有batch训练loss的累加\n",
    "    total_steps = 0 # 训练步数\n",
    "    \n",
    "    with tqdm(total=num_batches) as t:\n",
    "        for src, src_len, trg in iterator():\n",
    "            # 当前batch数据的loss\n",
    "            loss = forward_fn(src, trg, src_pad_idx, trg_pad_idx)\n",
    "            total_loss += loss.asnumpy()\n",
    "            total_steps += 1\n",
    "            # 当前的平均loss\n",
    "            curr_loss = total_loss / total_steps \n",
    "            t.set_postfix({'loss': f'{curr_loss:.2f}'})\n",
    "            t.update(1)\n",
    "    \n",
    "    return total_loss / total_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0:   2%|▏         | 4/226 [03:24<3:09:21, 51.18s/it, loss=8.22]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Administrator\\mindspore-examples-seq2seq\\Attention is All You Need.ipynb Cell 25\u001b[0m in \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Administrator/mindspore-examples-seq2seq/Attention%20is%20All%20You%20Need.ipynb#X33sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# mindspore.set_context(mode=mindspore.PYNATIVE_MODE)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Administrator/mindspore-examples-seq2seq/Attention%20is%20All%20You%20Need.ipynb#X33sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# mindspore.set_context(mode=mindspore.GRAPH_MODE)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Administrator/mindspore-examples-seq2seq/Attention%20is%20All%20You%20Need.ipynb#X33sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Administrator/mindspore-examples-seq2seq/Attention%20is%20All%20You%20Need.ipynb#X33sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m# 模型训练，网络权重更新\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Administrator/mindspore-examples-seq2seq/Attention%20is%20All%20You%20Need.ipynb#X33sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     train_loss \u001b[39m=\u001b[39m train(train_iterator, i)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Administrator/mindspore-examples-seq2seq/Attention%20is%20All%20You%20Need.ipynb#X33sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m# 网络权重更新后对模型进行验证\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Administrator/mindspore-examples-seq2seq/Attention%20is%20All%20You%20Need.ipynb#X33sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     valid_loss \u001b[39m=\u001b[39m evaluate(valid_iterator)\n",
      "\u001b[1;32mc:\\Users\\Administrator\\mindspore-examples-seq2seq\\Attention is All You Need.ipynb Cell 25\u001b[0m in \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Administrator/mindspore-examples-seq2seq/Attention%20is%20All%20You%20Need.ipynb#X33sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m t\u001b[39m.\u001b[39mset_description(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch: \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Administrator/mindspore-examples-seq2seq/Attention%20is%20All%20You%20Need.ipynb#X33sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mfor\u001b[39;00m src, src_len, trg \u001b[39min\u001b[39;00m iterator():\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Administrator/mindspore-examples-seq2seq/Attention%20is%20All%20You%20Need.ipynb#X33sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m# 计算当前batch数据的loss\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Administrator/mindspore-examples-seq2seq/Attention%20is%20All%20You%20Need.ipynb#X33sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     loss \u001b[39m=\u001b[39m train_step(src, trg, src_pad_idx, trg_pad_idx)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Administrator/mindspore-examples-seq2seq/Attention%20is%20All%20You%20Need.ipynb#X33sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39masnumpy()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Administrator/mindspore-examples-seq2seq/Attention%20is%20All%20You%20Need.ipynb#X33sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     total_steps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[1;32mc:\\Users\\Administrator\\mindspore-examples-seq2seq\\Attention is All You Need.ipynb Cell 25\u001b[0m in \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Administrator/mindspore-examples-seq2seq/Attention%20is%20All%20You%20Need.ipynb#X33sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39m\"\"\"单步训练\"\"\"\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Administrator/mindspore-examples-seq2seq/Attention%20is%20All%20You%20Need.ipynb#X33sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39m# 计算损失与梯度\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Administrator/mindspore-examples-seq2seq/Attention%20is%20All%20You%20Need.ipynb#X33sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m loss, grads \u001b[39m=\u001b[39m grad_fn(src, trg, src_pad_idx, trg_pad_idx)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Administrator/mindspore-examples-seq2seq/Attention%20is%20All%20You%20Need.ipynb#X33sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39m# 更新网络权重\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Administrator/mindspore-examples-seq2seq/Attention%20is%20All%20You%20Need.ipynb#X33sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m opt(grads)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\miniconda3\\envs\\mindspore_2.0_0316\\lib\\site-packages\\mindspore\\ops\\composite\\base.py:604\u001b[0m, in \u001b[0;36m_Grad.__call__.<locals>.after_grad\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    603\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mafter_grad\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 604\u001b[0m     \u001b[39mreturn\u001b[39;00m grad_(fn_, weights)(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\miniconda3\\envs\\mindspore_2.0_0316\\lib\\site-packages\\mindspore\\common\\api.py:101\u001b[0m, in \u001b[0;36m_wrap_func.<locals>.wrapper\u001b[1;34m(*arg, **kwargs)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[39m@wraps\u001b[39m(fn)\n\u001b[0;32m    100\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39marg, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 101\u001b[0m     results \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49marg, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    102\u001b[0m     \u001b[39mreturn\u001b[39;00m _convert_python_data(results)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\miniconda3\\envs\\mindspore_2.0_0316\\lib\\site-packages\\mindspore\\ops\\composite\\base.py:583\u001b[0m, in \u001b[0;36m_Grad.__call__.<locals>.after_grad\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    581\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pynative_forward_run(fn, grad_, weights, args, kwargs)\n\u001b[0;32m    582\u001b[0m _pynative_executor\u001b[39m.\u001b[39mgrad(fn, grad_, weights, grad_position, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 583\u001b[0m out \u001b[39m=\u001b[39m _pynative_executor()\n\u001b[0;32m    584\u001b[0m out \u001b[39m=\u001b[39m _grads_divided_by_device_num_if_recomputation(out)\n\u001b[0;32m    585\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_ids \u001b[39mand\u001b[39;00m out:\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\miniconda3\\envs\\mindspore_2.0_0316\\lib\\site-packages\\mindspore\\common\\api.py:1012\u001b[0m, in \u001b[0;36m_PyNativeExecutor.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1005\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m   1006\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1007\u001b[0m \u001b[39m    PyNative executor run grad graph.\u001b[39;00m\n\u001b[0;32m   1008\u001b[0m \n\u001b[0;32m   1009\u001b[0m \u001b[39m    Return:\u001b[39;00m\n\u001b[0;32m   1010\u001b[0m \u001b[39m        The return object after running grad graph.\u001b[39;00m\n\u001b[0;32m   1011\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1012\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_executor()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from mindspore import save_checkpoint\n",
    "\n",
    "num_epochs = 1 # 训练迭代数\n",
    "best_valid_loss = float('inf') # 当前最佳验证损失\n",
    "ckpt_file_name = os.path.join(cache_dir, 'transformer.ckpt') # 模型保存路径\n",
    "\n",
    "# mindspore.set_context(mode=mindspore.PYNATIVE_MODE)\n",
    "# mindspore.set_context(mode=mindspore.GRAPH_MODE)\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    # 模型训练，网络权重更新\n",
    "    train_loss = train(train_iterator, i)\n",
    "    # 网络权重更新后对模型进行验证\n",
    "    valid_loss = evaluate(valid_iterator)\n",
    "    \n",
    "    # 保存当前效果最好的模型\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        save_checkpoint(model, ckpt_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def translate_sentence(sentence, de_vocab, en_vocab, model, max_len=32):\n",
    "    \"\"\"给定德语句子，返回英文翻译\"\"\"\n",
    "    model.set_train(False)\n",
    "    # 对输入句子进行分词\n",
    "    if isinstance(sentence, str):\n",
    "        tokens = [token.lower() for token in re.findall(r'\\w+|[^\\w\\s]', sentence.rstrip())]\n",
    "    else:\n",
    "        tokens = [token.lower() for token in sentence]\n",
    "    \n",
    "    # 补充起始、终止占位符，统一序列长度\n",
    "    if len(tokens) > max_len - 2:\n",
    "        src_len = max_len\n",
    "        tokens = ['<bos>'] + tokens[:max_len - 2] + ['<eos>']\n",
    "    else:\n",
    "        src_len = len(tokens) + 2\n",
    "        tokens = ['<bos>'] + tokens + ['<eos>'] + ['<pad>'] * (max_len - src_len)\n",
    "        \n",
    "    # 将德语单词转化为数字索引\n",
    "    src = de_vocab.encode(tokens)\n",
    "    src = mindspore.Tensor(src, mindspore.int32).expand_dims(1)\n",
    "    src_len = mindspore.Tensor([src_len], mindspore.int32)\n",
    "    trg = mindspore.Tensor([en_vocab.bos_idx], mindspore.int32).expand_dims(1)\n",
    "    \n",
    "    # 获得预测结果，并将其转化为英语单词\n",
    "    outputs = model(src, trg, src_pad_idx, trg_pad_idx)\n",
    "    print(outputs.shape)\n",
    "    trg_indexes = [int(i.argmax(1).asnumpy()) for i in outputs.squeeze()]\n",
    "    eos_idx = trg_indexes.index(en_vocab.eos_idx) if en_vocab.eos_idx in trg_indexes else -1\n",
    "    trg_tokens = en_vocab.decode(trg_indexes[:eos_idx])\n",
    "    \n",
    "    return trg_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "For 'load_checkpoint', the checkpoint file: C:\\Users\\Administrator\\.mindspore_examples\\transformer.ckpt does not exist, please check whether the 'ckpt_file_name' is correct.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Administrator\\mindspore-examples-seq2seq\\Attention is All You Need.ipynb Cell 27\u001b[0m in \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Administrator/mindspore-examples-seq2seq/Attention%20is%20All%20You%20Need.ipynb#X66sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmindspore\u001b[39;00m \u001b[39mimport\u001b[39;00m load_checkpoint, load_param_into_net\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Administrator/mindspore-examples-seq2seq/Attention%20is%20All%20You%20Need.ipynb#X66sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# 加载之前训练好的模型\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Administrator/mindspore-examples-seq2seq/Attention%20is%20All%20You%20Need.ipynb#X66sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m param_dict \u001b[39m=\u001b[39m load_checkpoint(ckpt_file_name)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Administrator/mindspore-examples-seq2seq/Attention%20is%20All%20You%20Need.ipynb#X66sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m load_param_into_net(model, param_dict)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\miniconda3\\envs\\mindspore_2.0_0316\\lib\\site-packages\\mindspore\\train\\serialization.py:823\u001b[0m, in \u001b[0;36mload_checkpoint\u001b[1;34m(ckpt_file_name, net, strict_load, filter_prefix, dec_key, dec_mode, specify_prefix, choice_func)\u001b[0m\n\u001b[0;32m    752\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_checkpoint\u001b[39m(ckpt_file_name, net\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, strict_load\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, filter_prefix\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    753\u001b[0m                     dec_key\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dec_mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAES-GCM\u001b[39m\u001b[39m\"\u001b[39m, specify_prefix\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, choice_func\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    754\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    755\u001b[0m \u001b[39m    Load checkpoint info from a specified file.\u001b[39;00m\n\u001b[0;32m    756\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    821\u001b[0m \u001b[39m        {'conv1.weight': Parameter (name=conv1.weight, shape=(6, 1, 5, 5), dtype=Float32, requires_grad=True)}\u001b[39;00m\n\u001b[0;32m    822\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 823\u001b[0m     ckpt_file_name \u001b[39m=\u001b[39m _check_ckpt_file_name(ckpt_file_name)\n\u001b[0;32m    824\u001b[0m     specify_prefix \u001b[39m=\u001b[39m _check_prefix(specify_prefix)\n\u001b[0;32m    825\u001b[0m     filter_prefix \u001b[39m=\u001b[39m _check_prefix(filter_prefix)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\miniconda3\\envs\\mindspore_2.0_0316\\lib\\site-packages\\mindspore\\train\\serialization.py:903\u001b[0m, in \u001b[0;36m_check_ckpt_file_name\u001b[1;34m(ckpt_file_name)\u001b[0m\n\u001b[0;32m    901\u001b[0m ckpt_file_name \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mabspath(ckpt_file_name)\n\u001b[0;32m    902\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(ckpt_file_name):\n\u001b[1;32m--> 903\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mFor \u001b[39m\u001b[39m'\u001b[39m\u001b[39mload_checkpoint\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, the checkpoint file: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m does not exist, please check \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    904\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mwhether the \u001b[39m\u001b[39m'\u001b[39m\u001b[39mckpt_file_name\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is correct.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(ckpt_file_name))\n\u001b[0;32m    906\u001b[0m \u001b[39mreturn\u001b[39;00m ckpt_file_name\n",
      "\u001b[1;31mValueError\u001b[0m: For 'load_checkpoint', the checkpoint file: C:\\Users\\Administrator\\.mindspore_examples\\transformer.ckpt does not exist, please check whether the 'ckpt_file_name' is correct."
     ]
    }
   ],
   "source": [
    "from mindspore import load_checkpoint, load_param_into_net\n",
    "\n",
    "# 加载之前训练好的模型\n",
    "param_dict = load_checkpoint(ckpt_file_name)\n",
    "load_param_into_net(model, param_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src = ['ein', 'mann', 'mit', 'einem', 'orangefarbenen', 'hut', ',', 'der', 'etwas', 'anstarrt', '.']\n",
      "trg = ['a', 'man', 'in', 'an', 'orange', 'hat', 'starring', 'at', 'something', '.']\n"
     ]
    }
   ],
   "source": [
    "# 以测试数据集中的第一组语句为例，进行测试\n",
    "example_idx = 0\n",
    "\n",
    "src = test_dataset[example_idx][0]\n",
    "trg = test_dataset[example_idx][1]\n",
    "\n",
    "print(f'src = {src}')\n",
    "print(f'trg = {trg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0: 100%|██████████| 226/226 [14:24:12<00:00, 229.44s/it, loss=5.54]     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.544284820556641"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(train_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter (name=embedding_table, shape=(7853, 512), dtype=Float32, requires_grad=True)\n",
      "(128, 32)\n",
      "(128, 32, 512)\n",
      "(128, 32, 512)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'get_enc_dec_mask' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Administrator\\mindspore-examples-seq2seq\\Attention is All You Need.ipynb Cell 30\u001b[0m in \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Administrator/mindspore-examples-seq2seq/Attention%20is%20All%20You%20Need.ipynb#X41sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mprint\u001b[39m(src_content_emb(src)\u001b[39m.\u001b[39mshape)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Administrator/mindspore-examples-seq2seq/Attention%20is%20All%20You%20Need.ipynb#X41sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# encoder与decoder中的掩码\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Administrator/mindspore-examples-seq2seq/Attention%20is%20All%20You%20Need.ipynb#X41sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m# 将dec_self_attn_mask的shape变为[batch size * n_head, trg len, trg len]\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Administrator/mindspore-examples-seq2seq/Attention%20is%20All%20You%20Need.ipynb#X41sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m enc_self_attn_mask, dec_self_attn_mask, dec_enc_attn_mask \u001b[39m=\u001b[39m get_enc_dec_mask(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Administrator/mindspore-examples-seq2seq/Attention%20is%20All%20You%20Need.ipynb#X41sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     src, trg, src_pad_idx, trg_pad_idx)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Administrator/mindspore-examples-seq2seq/Attention%20is%20All%20You%20Need.ipynb#X41sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m dec_self_attn_mask \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mtile(dec_self_attn_mask, (n_head, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Administrator/mindspore-examples-seq2seq/Attention%20is%20All%20You%20Need.ipynb#X41sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_enc_dec_mask' is not defined"
     ]
    }
   ],
   "source": [
    "d_model = 512  # Embedding层维度\n",
    "n_head = 8  # 多头感知机中头的数量\n",
    "n_layer = 6  # 编码器和解码器的层数\n",
    "d_ff = 2048  # 前馈神经网络维度\n",
    "max_len = 32  # 序列最大长度\n",
    "\n",
    "compute_dtype = mindspore.float32\n",
    "\n",
    "positional_encoding = PositionalEncoding(d_model, max_len=max_len + 1)  # 位置掩码\n",
    "src_content_emb = nn.Embedding(len(de_vocab), d_model)  # 源序列embedding\n",
    "trg_content_emb = nn.Embedding(len(en_vocab), d_model)  # 目标序列embedding\n",
    "src_pad_idx = de_vocab.pad_idx  # 源序列中<pad>占位符索引\n",
    "trg_pad_idx = en_vocab.pad_idx  # 目标序列中<pad>占位符索引\n",
    "src_vocab_size = len(de_vocab)\n",
    "trg_vocab_size = len(en_vocab)\n",
    "\n",
    "for src, src_len, trg in test_iterator():\n",
    "    # 计算源序列与目标序列的embedding，并加入位置编码\n",
    "    # 为平衡原embedding和位置编码的数值，将原embedding以适当比例放大\n",
    "    content_scale = ops.sqrt(mindspore.Tensor([d_model], mindspore.float32))\n",
    "    src_emb = positional_encoding(src_content_emb(src) * content_scale)\n",
    "    trg_emb = positional_encoding(trg_content_emb(trg) * content_scale)\n",
    "    for param in src_content_emb.get_parameters():\n",
    "        print(param)\n",
    "    print(src.shape)\n",
    "    print(src_emb.shape)\n",
    "    print(src_content_emb(src).shape)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(iterator):\n",
    "    \"\"\"模型验证\"\"\"\n",
    "    model.set_train(False)\n",
    "    num_batches = len(iterator)\n",
    "    total_loss = 0 # 所有batch训练loss的累加\n",
    "    total_steps = 0 # 训练步数\n",
    "    \n",
    "    with tqdm(total=num_batches) as t:\n",
    "        for src, src_len, trg in iterator():\n",
    "            src_emb = embedding(src, de_vocab, max_len, d_model)\n",
    "            trg_emb = embedding(trg, en_vocab, max_len, d_model)\n",
    "            loss = forward_fn(src_emb, trg_emb) # 当前batch的loss\n",
    "            total_loss += loss.asnumpy()\n",
    "            total_steps += 1\n",
    "            curr_loss = total_loss / total_steps # 当前的平均loss\n",
    "            t.set_postfix({'loss': f'{curr_loss:.2f}'})\n",
    "            t.update(1)\n",
    "    \n",
    "    return total_loss / total_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import mindspore\n",
    "import mindspore.ops as ops\n",
    "import mindspore.numpy as mnp\n",
    "import numpy as np\n",
    "from mindspore import Tensor\n",
    "max_len = 32\n",
    "ones = ops.ones((max_len, max_len), mindspore.float32)\n",
    "subsequent_mask = ones.triu(diagonal=1)\n",
    "dec_self_attn_subsequent_mask = get_attn_subsequent_mask(subsequent_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5893\n",
      "7853\n"
     ]
    }
   ],
   "source": [
    "print(len(en_vocab))\n",
    "print(len(de_vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add & Norm\n",
    "\n",
    "- Add\n",
    "- Norm： Layer Norm\n",
    "\n",
    "### 前馈神经网络（Feed-Forward Nerual Network，FFN）\n",
    "\n",
    "- Pointwise FFN\n",
    "\n",
    "### 编码器（Encoder）\n",
    "\n",
    "### 解码器（Decoder）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore.nn as nn\n",
    "import mindspore.ops as ops\n",
    "\n",
    "d_model = 512  # Embedding层维度\n",
    "n_head = 8  # 多头感知机中头的数量\n",
    "n_layer = 6  # 编码器和解码器的层数\n",
    "d_ff = 2048  # 前馈神经网络维度\n",
    "max_len = 32  # 序列最大长度\n",
    "\n",
    "\n",
    "model = nn.Transformer()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = nn.Adam(model.trainable_params(), learning_rate=0.0001)\n",
    "\n",
    "def forward_fn(src, trg):\n",
    "    output = model(src, trg)\n",
    "    loss = loss_fn(output, trg)\n",
    "\n",
    "    return loss\n",
    "\n",
    "grad_fn = mindspore.value_and_grad(forward_fn, None, opt.parameters)\n",
    "\n",
    "def train_step(src, trg):\n",
    "    loss, grads = grad_fn(src, trg)\n",
    "    opt(grads)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False False False ...  True  True  True]\n",
      " [False False False ...  True  True  True]\n",
      " [False False False ...  True  True  True]\n",
      " ...\n",
      " [False False False ...  True  True  True]\n",
      " [False False False ...  True  True  True]\n",
      " [False False False ...  True  True  True]]\n"
     ]
    }
   ],
   "source": [
    "for src, src_len, trg in test_iterator():\n",
    "    mask = ops.equal(src, 1)\n",
    "    print(mask)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "For 'Add', the type of 'x' must be one of Tensor[Int8], Tensor[Int16], Tensor[Int32], Tensor[Int64], Tensor[UInt8], Tensor[UInt16], Tensor[UInt32], Tensor[UInt64], Tensor[Float16], Tensor[Float32], Tensor[Float64], Tensor[Complex64], Tensor[Complex128], but got Tensor[Bool].The supported data types depend on the hardware that executes the operator, for more details, please refer to the MindSpore official website to get more information about the data type.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [45], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m dec_self_attn_pad_mask \u001b[39m=\u001b[39m get_attn_pad_mask(trg, trg, \u001b[39m1\u001b[39m)\n\u001b[0;32m     20\u001b[0m dec_self_attn_subsequent_mask \u001b[39m=\u001b[39m get_attn_subsequent_mask(dec_self_attn_pad_mask)\n\u001b[1;32m---> 21\u001b[0m dec_self_attn_mask \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mgt((dec_self_attn_pad_mask \u001b[39m+\u001b[39;49m dec_self_attn_subsequent_mask), \u001b[39m0\u001b[39m)\n\u001b[0;32m     23\u001b[0m dec_enc_attn_mask \u001b[39m=\u001b[39m get_attn_pad_mask(trg, src, \u001b[39m1\u001b[39m)\n\u001b[0;32m     25\u001b[0m \u001b[39mprint\u001b[39m(dec_self_attn_mask\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\miniconda3\\envs\\mindspore_2.0_0227\\lib\\site-packages\\mindspore\\common\\tensor.py:325\u001b[0m, in \u001b[0;36mTensor.__add__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__add__\u001b[39m(\u001b[39mself\u001b[39m, other):\n\u001b[1;32m--> 325\u001b[0m     \u001b[39mreturn\u001b[39;00m tensor_operator_registry\u001b[39m.\u001b[39;49mget(\u001b[39m'\u001b[39;49m\u001b[39m__add__\u001b[39;49m\u001b[39m'\u001b[39;49m)(\u001b[39mself\u001b[39;49m, other)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\miniconda3\\envs\\mindspore_2.0_0227\\lib\\site-packages\\mindspore\\ops\\composite\\multitype_ops\\_compile_utils.py:103\u001b[0m, in \u001b[0;36m_tensor_add\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(other, COOTensor):\n\u001b[0;32m    102\u001b[0m     \u001b[39mreturn\u001b[39;00m other \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\n\u001b[1;32m--> 103\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49madd(\u001b[39mself\u001b[39;49m, other)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\miniconda3\\envs\\mindspore_2.0_0227\\lib\\site-packages\\mindspore\\ops\\function\\math_func.py:308\u001b[0m, in \u001b[0;36madd\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39madd\u001b[39m(x, y):\n\u001b[0;32m    257\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[39m    Adds two input tensors element-wise.\u001b[39;00m\n\u001b[0;32m    259\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[39m        Float32\u001b[39;00m\n\u001b[0;32m    307\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 308\u001b[0m     \u001b[39mreturn\u001b[39;00m tensor_add(x, y)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\miniconda3\\envs\\mindspore_2.0_0227\\lib\\site-packages\\mindspore\\ops\\primitive.py:317\u001b[0m, in \u001b[0;36mPrimitive.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[39mif\u001b[39;00m should_elim:\n\u001b[0;32m    316\u001b[0m     \u001b[39mreturn\u001b[39;00m output\n\u001b[1;32m--> 317\u001b[0m \u001b[39mreturn\u001b[39;00m _run_op(\u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname, args)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\miniconda3\\envs\\mindspore_2.0_0227\\lib\\site-packages\\mindspore\\ops\\primitive.py:885\u001b[0m, in \u001b[0;36m_run_op\u001b[1;34m(obj, op_name, args)\u001b[0m\n\u001b[0;32m    883\u001b[0m     stub \u001b[39m=\u001b[39m _pynative_executor\u001b[39m.\u001b[39mrun_op_async(obj, args)\n\u001b[0;32m    884\u001b[0m     \u001b[39mreturn\u001b[39;00m _convert_stub(stub)\n\u001b[1;32m--> 885\u001b[0m \u001b[39mreturn\u001b[39;00m _run_op_sync(obj, op_name, args)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\miniconda3\\envs\\mindspore_2.0_0227\\lib\\site-packages\\mindspore\\common\\api.py:101\u001b[0m, in \u001b[0;36m_wrap_func.<locals>.wrapper\u001b[1;34m(*arg, **kwargs)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[39m@wraps\u001b[39m(fn)\n\u001b[0;32m    100\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39marg, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 101\u001b[0m     results \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49marg, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    102\u001b[0m     \u001b[39mreturn\u001b[39;00m _convert_python_data(results)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\miniconda3\\envs\\mindspore_2.0_0227\\lib\\site-packages\\mindspore\\ops\\primitive.py:891\u001b[0m, in \u001b[0;36m_run_op_sync\u001b[1;34m(obj, op_name, args)\u001b[0m\n\u001b[0;32m    888\u001b[0m \u001b[39m@_wrap_func\u001b[39m\n\u001b[0;32m    889\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_op_sync\u001b[39m(obj, op_name, args):\n\u001b[0;32m    890\u001b[0m     \u001b[39m\"\"\"Single op execution function in synchronous mode.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 891\u001b[0m     output \u001b[39m=\u001b[39m _pynative_executor\u001b[39m.\u001b[39;49mreal_run_op(obj, op_name, args)\n\u001b[0;32m    892\u001b[0m     \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\miniconda3\\envs\\mindspore_2.0_0227\\lib\\site-packages\\mindspore\\common\\api.py:1039\u001b[0m, in \u001b[0;36m_PyNativeExecutor.real_run_op\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1029\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreal_run_op\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs):\n\u001b[0;32m   1030\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1031\u001b[0m \u001b[39m    Run single op.\u001b[39;00m\n\u001b[0;32m   1032\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1037\u001b[0m \u001b[39m        Tensor, result of run op.\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1039\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_executor\u001b[39m.\u001b[39;49mreal_run_op(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\miniconda3\\envs\\mindspore_2.0_0227\\lib\\site-packages\\mindspore\\ops\\primitive.py:642\u001b[0m, in \u001b[0;36mPrimitiveWithInfer.__infer__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    640\u001b[0m     fn \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m'\u001b[39m\u001b[39minfer_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m track)\n\u001b[0;32m    641\u001b[0m     \u001b[39m# fn may return None\u001b[39;00m\n\u001b[1;32m--> 642\u001b[0m     out[track] \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49m(x[track] \u001b[39mfor\u001b[39;49;00m x \u001b[39min\u001b[39;49;00m args))\n\u001b[0;32m    644\u001b[0m \u001b[39m# output does not contain dynamic shape, no need to calculate min/max shape\u001b[39;00m\n\u001b[0;32m    646\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhas_dynamic_shape\u001b[39m(shp):\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\miniconda3\\envs\\mindspore_2.0_0227\\lib\\site-packages\\mindspore\\ops\\operations\\math_ops.py:115\u001b[0m, in \u001b[0;36m_MathBinaryOp.infer_dtype\u001b[1;34m(self, x_dtype, y_dtype)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minfer_dtype\u001b[39m(\u001b[39mself\u001b[39m, x_dtype, y_dtype):\n\u001b[1;32m--> 115\u001b[0m     \u001b[39mreturn\u001b[39;00m _MathBinaryOp\u001b[39m.\u001b[39;49mdo_infer_dtype(x_dtype, y_dtype, mstype\u001b[39m.\u001b[39;49mnumber_type, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\miniconda3\\envs\\mindspore_2.0_0227\\lib\\site-packages\\mindspore\\ops\\operations\\math_ops.py:111\u001b[0m, in \u001b[0;36m_MathBinaryOp.do_infer_dtype\u001b[1;34m(x_dtype, y_dtype, valid_dtype, prim_name)\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mComplex math binary op expecting Tensor [Complex64, Complex64],\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    106\u001b[0m                         \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m[Complex64, Float32], [Float32, Complex64], [Complex128, Complex128],\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    107\u001b[0m                         \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m[Complex128, Float64], [Float64, Complex128],\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    108\u001b[0m                         \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbut got : [\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mformat\u001b[39m(x_dtype)\u001b[39m}\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mformat\u001b[39m(y_dtype)\u001b[39m}\u001b[39;00m\u001b[39m].\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    109\u001b[0m     \u001b[39mreturn\u001b[39;00m type_infer_dict\u001b[39m.\u001b[39mget((x_dtype\u001b[39m.\u001b[39melement_type(), y_dtype\u001b[39m.\u001b[39melement_type()))\n\u001b[1;32m--> 111\u001b[0m validator\u001b[39m.\u001b[39;49mcheck_tensors_dtypes_same_and_valid(args_type, valid_dtype, prim_name)\n\u001b[0;32m    112\u001b[0m \u001b[39mreturn\u001b[39;00m x_dtype\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\miniconda3\\envs\\mindspore_2.0_0227\\lib\\site-packages\\mindspore\\_checkparam.py:682\u001b[0m, in \u001b[0;36mValidator.check_tensors_dtypes_same_and_valid\u001b[1;34m(args, valid_dtypes, prim_name)\u001b[0m\n\u001b[0;32m    680\u001b[0m valid_dtypes \u001b[39m=\u001b[39m valid_dtypes \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(valid_dtypes, Iterable) \u001b[39melse\u001b[39;00m [valid_dtypes]\n\u001b[0;32m    681\u001b[0m tensor_types \u001b[39m=\u001b[39m [mstype\u001b[39m.\u001b[39mtensor_type(t) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m valid_dtypes]\n\u001b[1;32m--> 682\u001b[0m Validator\u001b[39m.\u001b[39;49mcheck_types_same_and_valid(args, tensor_types, prim_name)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\miniconda3\\envs\\mindspore_2.0_0227\\lib\\site-packages\\mindspore\\_checkparam.py:675\u001b[0m, in \u001b[0;36mValidator.check_types_same_and_valid\u001b[1;34m(args, valid_values, prim_name)\u001b[0m\n\u001b[0;32m    672\u001b[0m     \u001b[39mreturn\u001b[39;00m arg1\n\u001b[0;32m    674\u001b[0m elem_types \u001b[39m=\u001b[39m \u001b[39mmap\u001b[39m(_check_type_valid, args\u001b[39m.\u001b[39mitems())\n\u001b[1;32m--> 675\u001b[0m reduce(_check_types_same, elem_types)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\miniconda3\\envs\\mindspore_2.0_0227\\lib\\site-packages\\mindspore\\_checkparam.py:662\u001b[0m, in \u001b[0;36mValidator.check_types_same_and_valid.<locals>._check_type_valid\u001b[1;34m(arg)\u001b[0m\n\u001b[0;32m    660\u001b[0m arg_key, arg_val \u001b[39m=\u001b[39m arg\n\u001b[0;32m    661\u001b[0m elem_type \u001b[39m=\u001b[39m arg_val\n\u001b[1;32m--> 662\u001b[0m Validator\u001b[39m.\u001b[39;49mcheck_subclass(arg_key, elem_type, valid_values, prim_name)\n\u001b[0;32m    663\u001b[0m \u001b[39mreturn\u001b[39;00m (arg_key, elem_type)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\miniconda3\\envs\\mindspore_2.0_0227\\lib\\site-packages\\mindspore\\_checkparam.py:641\u001b[0m, in \u001b[0;36mValidator.check_subclass\u001b[1;34m(arg_name, type_, template_types, prim_name, addition_error_info)\u001b[0m\n\u001b[0;32m    639\u001b[0m     addition_error_info \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m addition_error_info\n\u001b[0;32m    640\u001b[0m type_str \u001b[39m=\u001b[39m (\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtype \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(type_)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(type_, (\u001b[39mtuple\u001b[39m, \u001b[39mlist\u001b[39m)) \u001b[39melse\u001b[39;00m \u001b[39mstr\u001b[39m(type_))\n\u001b[1;32m--> 641\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFor \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mprim_name\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, the type of \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00marg_name\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    642\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m must be \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39mone of \u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(template_types) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    643\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin((\u001b[39mstr\u001b[39m(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m template_types))\u001b[39m}\u001b[39;00m\u001b[39m, but got \u001b[39m\u001b[39m{\u001b[39;00mtype_str\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    644\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00maddition_error_info\u001b[39m}\u001b[39;00m\u001b[39m.The supported data types depend on the hardware that\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    645\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m executes the operator, for more details, please refer to the MindSpore official \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    646\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwebsite to get more information about the data type.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: For 'Add', the type of 'x' must be one of Tensor[Int8], Tensor[Int16], Tensor[Int32], Tensor[Int64], Tensor[UInt8], Tensor[UInt16], Tensor[UInt32], Tensor[UInt64], Tensor[Float16], Tensor[Float32], Tensor[Float64], Tensor[Complex64], Tensor[Complex128], but got Tensor[Bool].The supported data types depend on the hardware that executes the operator, for more details, please refer to the MindSpore official website to get more information about the data type."
     ]
    }
   ],
   "source": [
    "def get_attn_pad_mask(seq_q, seq_k, pad_idx):\n",
    "    # print(seq_q.shape)\n",
    "    batch_size, len_q = seq_q.shape\n",
    "    batch_size, len_k = seq_k.shape\n",
    "\n",
    "    pad_attn_mask = ops.equal(seq_k, pad_idx)\n",
    "    pad_attn_mask = pad_attn_mask.expand_dims(1)\n",
    "\n",
    "    return ops.broadcast_to(pad_attn_mask, (batch_size, len_q, len_k))\n",
    "\n",
    "def get_attn_subsequent_mask(subsequent_mask):\n",
    "    subsequent_mask = subsequent_mask.expand_dims(0)\n",
    "    return subsequent_mask\n",
    "\n",
    "for src, src_len, trg in test_iterator():\n",
    "    # src_emb = nn.Embedding(len(de_vocab), d_model)(src)\n",
    "    # trg_emb = nn.Embedding(len(en_vocab), d_model)(trg)\n",
    "\n",
    "    dec_self_attn_pad_mask = get_attn_pad_mask(trg, trg, 1)\n",
    "    dec_self_attn_subsequent_mask = get_attn_subsequent_mask(dec_self_attn_pad_mask)\n",
    "    dec_self_attn_mask = ops.gt((dec_self_attn_pad_mask + dec_self_attn_subsequent_mask), 0)\n",
    "\n",
    "    dec_enc_attn_mask = get_attn_pad_mask(trg, src, 1)\n",
    "\n",
    "    print(dec_self_attn_mask.shape)\n",
    "\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindspore.ops.function.nn_func import multi_head_attention_forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 32, 512)\n",
      "(128, 32, 512)\n"
     ]
    }
   ],
   "source": [
    "import mindspore\n",
    "import mindspore.nn as nn\n",
    "import mindspore.ops as ops\n",
    "from mindspore import Tensor\n",
    "\n",
    "d_model = 512  # Embedding层维度\n",
    "n_head = 8  # 多头感知机中头的数量\n",
    "n_layer = 6  # 编码器和解码器的层数\n",
    "d_ff = 2048  # 前馈神经网络维度\n",
    "max_len = 32  # 序列最大长度\n",
    "\n",
    "compute_dtype = mindspore.float32\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Cell):\n",
    "    \"\"\"位置编码\"\"\"\n",
    "    def __init__(self, embed_dim, dropout=0.1, max_len=100):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # 位置信息\n",
    "        # shape = [1, max len, embed dim]\n",
    "        self.pos = ops.fill(compute_dtype, (1, max_len, embed_dim), 0)\n",
    "        angle = ops.arange(end=max_len, dtype=compute_dtype).reshape(\n",
    "            -1, 1) / ops.pow(\n",
    "                10000,\n",
    "                ops.arange(end=embed_dim, step=2, dtype=compute_dtype) /\n",
    "                embed_dim)\n",
    "        self.pos[:, :, 0::2] = ops.sin(angle)\n",
    "        self.pos[:, :, 1::2] = ops.cos(angle)\n",
    "\n",
    "    def construct(self, x):\n",
    "        # 将位置编码截取至x同等大小\n",
    "        x = x + self.pos[:, :x.shape[1], :]\n",
    "        return self.dropout(x)\n",
    "    \n",
    "\n",
    "def get_key_padding_mask()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 512)\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from mindspore import Tensor\n",
    "import numpy as np\n",
    "\n",
    "def get_sinusoid_encoding_table(n_position, d_model):\n",
    "    def cal_angle(position, hid_idx):\n",
    "        return position / np.power(10000, 2 * (hid_idx // 2) / d_model)\n",
    "    def get_posi_angle_vec(position):\n",
    "        return [cal_angle(position, hid_j) for hid_j in range(d_model)]\n",
    "\n",
    "    sinusoid_table = np.array([get_posi_angle_vec(pos_i) for pos_i in range(n_position)])\n",
    "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])  # dim 2i\n",
    "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])  # dim 2i+1\n",
    "    return Tensor(sinusoid_table, mindspore.float32)\n",
    "\n",
    "\n",
    "def embedding(input, vocab, max_len, d_model):\n",
    "    tok_emb = nn.Embedding(len(vocab), d_model)\n",
    "    sinusoid_table = get_sinusoid_encoding_table(max_len, d_model)\n",
    "    pos_emb = nn.Embedding(sinusoid_table.shape[0], sinusoid_table.shape[1], embedding_table=sinusoid_table)\n",
    "    output = tok_emb(input) + pos_emb(input)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(iterator, epoch=0):\n",
    "    \"\"\"模型训练\"\"\"\n",
    "    model.set_train(True)\n",
    "    num_batches = len(iterator)\n",
    "    total_loss = 0 # 所有batch训练loss的累加\n",
    "    total_steps = 0 # 训练步数\n",
    "\n",
    "    with tqdm(total=num_batches) as t:\n",
    "        t.set_description(f'Epoch: {epoch}')\n",
    "        for src, src_len, trg in iterator():\n",
    "            src_emb = embedding(src, de_vocab, max_len, d_model)\n",
    "            trg_emb = embedding(trg, en_vocab, max_len, d_model)\n",
    "            # print(src_emb.shape)\n",
    "            # print(trg_emb.shape)\n",
    "            loss = train_step(src_emb, trg_emb) # 当前batch的loss\n",
    "            total_loss += loss.asnumpy()\n",
    "            total_steps += 1\n",
    "            curr_loss = total_loss / total_steps # 当前的平均loss\n",
    "            t.set_postfix({'loss': f'{curr_loss:.2f}'})\n",
    "            t.update(1)\n",
    "    \n",
    "    return total_loss / total_steps\n",
    "\n",
    "\n",
    "def evaluate(iterator):\n",
    "    \"\"\"模型验证\"\"\"\n",
    "    model.set_train(False)\n",
    "    num_batches = len(iterator)\n",
    "    total_loss = 0 # 所有batch训练loss的累加\n",
    "    total_steps = 0 # 训练步数\n",
    "    \n",
    "    with tqdm(total=num_batches) as t:\n",
    "        for src, src_len, trg in iterator():\n",
    "            src_emb = embedding(src, de_vocab, max_len, d_model)\n",
    "            trg_emb = embedding(trg, en_vocab, max_len, d_model)\n",
    "            loss = forward_fn(src_emb, trg_emb) # 当前batch的loss\n",
    "            total_loss += loss.asnumpy()\n",
    "            total_steps += 1\n",
    "            curr_loss = total_loss / total_steps # 当前的平均loss\n",
    "            t.set_postfix({'loss': f'{curr_loss:.2f}'})\n",
    "            t.update(1)\n",
    "    \n",
    "    return total_loss / total_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0: 100%|██████████| 226/226 [4:21:31<00:00, 69.43s/it, loss=41.43]     \n",
      "100%|██████████| 8/8 [00:58<00:00,  7.28s/it, loss=40.79]\n",
      "Epoch: 1: 100%|██████████| 226/226 [11:25:32<00:00, 182.00s/it, loss=40.83]    \n",
      "100%|██████████| 8/8 [00:32<00:00,  4.11s/it, loss=40.69]\n",
      "Epoch: 2: 100%|██████████| 226/226 [50:49<00:00, 13.49s/it, loss=40.71]\n",
      "100%|██████████| 8/8 [00:26<00:00,  3.33s/it, loss=40.62]\n",
      "Epoch: 3: 100%|██████████| 226/226 [50:12<00:00, 13.33s/it, loss=40.60]\n",
      "100%|██████████| 8/8 [00:29<00:00,  3.68s/it, loss=40.54]\n",
      "Epoch: 4:   6%|▌         | 14/226 [03:12<46:59, 13.30s/it, loss=40.80] "
     ]
    }
   ],
   "source": [
    "from mindspore import save_checkpoint\n",
    "\n",
    "num_epochs = 10 # 训练迭代数\n",
    "clip = 1.0 # 梯度裁剪阈值\n",
    "best_valid_loss = float('inf') # 当前最佳验证损失\n",
    "ckpt_file_name = os.path.join(cache_dir, 'transformer.ckpt') # 模型保存路径\n",
    "\n",
    "# mindspore.set_context(mode=mindspore.PYNATIVE_MODE)\n",
    "mindspore.set_context(mode=mindspore.GRAPH_MODE)\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    # 模型训练，网络权重更新\n",
    "    train_loss = train(train_iterator, i)\n",
    "    # 网络权重更新后对模型进行验证\n",
    "    valid_loss = evaluate(valid_iterator)\n",
    "    \n",
    "    # 保存当前效果最好的模型\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        save_checkpoint(model, ckpt_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_model: 512\n",
      "attn type after softmax:  <class 'mindspore.common.tensor.Tensor'>\n",
      "attn type after dropout: <class 'mindspore.common.tensor.Tensor'>\n",
      "attn type after softmax:  <class 'mindspore.common.tensor.Tensor'>\n",
      "attn type after dropout: <class 'mindspore.common.tensor.Tensor'>\n",
      "attn type after softmax:  <class 'mindspore.common.tensor.Tensor'>\n",
      "attn type after dropout: <class 'mindspore.common.tensor.Tensor'>\n",
      "attn type after softmax:  <class 'mindspore.common.tensor.Tensor'>\n",
      "attn type after dropout: <class 'mindspore.common.tensor.Tensor'>\n",
      "attn type after softmax:  <class 'mindspore.common.tensor.Tensor'>\n",
      "attn type after dropout: <class 'mindspore.common.tensor.Tensor'>\n",
      "attn type after softmax:  <class 'mindspore.common.tensor.Tensor'>\n",
      "attn type after dropout: <class 'mindspore.common.tensor.Tensor'>\n",
      "attn type after softmax:  <class 'mindspore.common.tensor.Tensor'>\n",
      "attn type after dropout: <class 'mindspore.common.tensor.Tensor'>\n",
      "attn type after softmax:  <class 'mindspore.common.tensor.Tensor'>\n",
      "attn type after dropout: <class 'mindspore.common.tensor.Tensor'>\n",
      "attn type after softmax:  <class 'mindspore.common.tensor.Tensor'>\n",
      "attn type after dropout: <class 'mindspore.common.tensor.Tensor'>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [13], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[39mreturn\u001b[39;00m loss\n\u001b[0;32m     21\u001b[0m net_work\u001b[39m.\u001b[39mset_train(\u001b[39mTrue\u001b[39;00m)   \n\u001b[1;32m---> 22\u001b[0m train_step(src, trg)\n",
      "Cell \u001b[1;32mIn [13], line 17\u001b[0m, in \u001b[0;36mtrain_step\u001b[1;34m(src, trg)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_step\u001b[39m(src, trg):\n\u001b[1;32m---> 17\u001b[0m     loss, grads \u001b[39m=\u001b[39m grad_fn(src, trg)\n\u001b[0;32m     18\u001b[0m     optimizer(grads)\n\u001b[0;32m     19\u001b[0m     \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\miniconda3\\envs\\mindspore_2.0_0227\\lib\\site-packages\\mindspore\\ops\\composite\\base.py:605\u001b[0m, in \u001b[0;36m_Grad.__call__.<locals>.after_grad\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    604\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mafter_grad\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 605\u001b[0m     \u001b[39mreturn\u001b[39;00m grad_(fn_, weights)(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\miniconda3\\envs\\mindspore_2.0_0227\\lib\\site-packages\\mindspore\\common\\api.py:101\u001b[0m, in \u001b[0;36m_wrap_func.<locals>.wrapper\u001b[1;34m(*arg, **kwargs)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[39m@wraps\u001b[39m(fn)\n\u001b[0;32m    100\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39marg, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 101\u001b[0m     results \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49marg, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    102\u001b[0m     \u001b[39mreturn\u001b[39;00m _convert_python_data(results)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\miniconda3\\envs\\mindspore_2.0_0227\\lib\\site-packages\\mindspore\\ops\\composite\\base.py:582\u001b[0m, in \u001b[0;36m_Grad.__call__.<locals>.after_grad\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    580\u001b[0m \u001b[39m@_wrap_func\u001b[39m\n\u001b[0;32m    581\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mafter_grad\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 582\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pynative_forward_run(fn, grad_, args, kwargs)\n\u001b[0;32m    583\u001b[0m     _pynative_executor\u001b[39m.\u001b[39mgrad(fn, grad_, weights, grad_position, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    584\u001b[0m     out \u001b[39m=\u001b[39m _pynative_executor()\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\miniconda3\\envs\\mindspore_2.0_0227\\lib\\site-packages\\mindspore\\ops\\composite\\base.py:631\u001b[0m, in \u001b[0;36m_Grad._pynative_forward_run\u001b[1;34m(self, fn, grad, args, kwargs)\u001b[0m\n\u001b[0;32m    629\u001b[0m _pynative_executor\u001b[39m.\u001b[39mset_grad_flag(\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    630\u001b[0m _pynative_executor\u001b[39m.\u001b[39mnew_graph(fn, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mnew_kwargs)\n\u001b[1;32m--> 631\u001b[0m outputs \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mnew_kwargs)\n\u001b[0;32m    632\u001b[0m _pynative_executor\u001b[39m.\u001b[39mend_graph(fn, outputs, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mnew_kwargs)\n\u001b[0;32m    633\u001b[0m \u001b[39mreturn\u001b[39;00m outputs\n",
      "Cell \u001b[1;32mIn [13], line 9\u001b[0m, in \u001b[0;36mforward_fn\u001b[1;34m(src, trg)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward_fn\u001b[39m(src, trg):\n\u001b[1;32m----> 9\u001b[0m     out \u001b[39m=\u001b[39m net_work(src, trg)\n\u001b[0;32m     10\u001b[0m     loss \u001b[39m=\u001b[39m loss_fn(out, trg)\n\u001b[0;32m     11\u001b[0m     \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\miniconda3\\envs\\mindspore_2.0_0227\\lib\\site-packages\\mindspore\\nn\\cell.py:653\u001b[0m, in \u001b[0;36mCell.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    651\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    652\u001b[0m     _pynative_executor\u001b[39m.\u001b[39mnew_graph(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 653\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_construct(args, kwargs)\n\u001b[0;32m    654\u001b[0m     _pynative_executor\u001b[39m.\u001b[39mend_graph(\u001b[39mself\u001b[39m, output, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    655\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\miniconda3\\envs\\mindspore_2.0_0227\\lib\\site-packages\\mindspore\\nn\\cell.py:441\u001b[0m, in \u001b[0;36mCell._run_construct\u001b[1;34m(self, cast_inputs, kwargs)\u001b[0m\n\u001b[0;32m    439\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shard_fn(\u001b[39m*\u001b[39mcast_inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    440\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 441\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconstruct(\u001b[39m*\u001b[39;49mcast_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    442\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_enable_forward_hook:\n\u001b[0;32m    443\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_forward_hook(cast_inputs, output)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\miniconda3\\envs\\mindspore_2.0_0227\\lib\\site-packages\\mindspore\\nn\\layer\\transformer.py:630\u001b[0m, in \u001b[0;36mTransformer.construct\u001b[1;34m(self, src, tgt, src_mask, tgt_mask, memory_mask, src_key_padding_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[0;32m    627\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mthe feature number of src and tgt must be equal to d_model\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    629\u001b[0m memory \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(src, mask\u001b[39m=\u001b[39msrc_mask, src_key_padding_mask\u001b[39m=\u001b[39msrc_key_padding_mask)\n\u001b[1;32m--> 630\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(tgt, memory, tgt_mask\u001b[39m=\u001b[39;49mtgt_mask, memory_mask\u001b[39m=\u001b[39;49mmemory_mask,\n\u001b[0;32m    631\u001b[0m                       tgt_key_padding_mask\u001b[39m=\u001b[39;49mtgt_key_padding_mask,\n\u001b[0;32m    632\u001b[0m                       memory_key_padding_mask\u001b[39m=\u001b[39;49mmemory_key_padding_mask)\n\u001b[0;32m    633\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\miniconda3\\envs\\mindspore_2.0_0227\\lib\\site-packages\\mindspore\\nn\\cell.py:653\u001b[0m, in \u001b[0;36mCell.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    651\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    652\u001b[0m     _pynative_executor\u001b[39m.\u001b[39mnew_graph(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 653\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_construct(args, kwargs)\n\u001b[0;32m    654\u001b[0m     _pynative_executor\u001b[39m.\u001b[39mend_graph(\u001b[39mself\u001b[39m, output, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    655\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\miniconda3\\envs\\mindspore_2.0_0227\\lib\\site-packages\\mindspore\\nn\\cell.py:441\u001b[0m, in \u001b[0;36mCell._run_construct\u001b[1;34m(self, cast_inputs, kwargs)\u001b[0m\n\u001b[0;32m    439\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shard_fn(\u001b[39m*\u001b[39mcast_inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    440\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 441\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconstruct(\u001b[39m*\u001b[39;49mcast_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    442\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_enable_forward_hook:\n\u001b[0;32m    443\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_forward_hook(cast_inputs, output)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\miniconda3\\envs\\mindspore_2.0_0227\\lib\\site-packages\\mindspore\\nn\\layer\\transformer.py:532\u001b[0m, in \u001b[0;36mTransformerDecoder.construct\u001b[1;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[0;32m    529\u001b[0m output \u001b[39m=\u001b[39m tgt\n\u001b[0;32m    531\u001b[0m \u001b[39mfor\u001b[39;00m mod \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m--> 532\u001b[0m     output \u001b[39m=\u001b[39m mod(output, memory, tgt_mask\u001b[39m=\u001b[39;49mtgt_mask,\n\u001b[0;32m    533\u001b[0m                  memory_mask\u001b[39m=\u001b[39;49mmemory_mask,\n\u001b[0;32m    534\u001b[0m                  tgt_key_padding_mask\u001b[39m=\u001b[39;49mtgt_key_padding_mask,\n\u001b[0;32m    535\u001b[0m                  memory_key_padding_mask\u001b[39m=\u001b[39;49mmemory_key_padding_mask)\n\u001b[0;32m    537\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    538\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm(output)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\miniconda3\\envs\\mindspore_2.0_0227\\lib\\site-packages\\mindspore\\nn\\cell.py:653\u001b[0m, in \u001b[0;36mCell.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    651\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    652\u001b[0m     _pynative_executor\u001b[39m.\u001b[39mnew_graph(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 653\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_construct(args, kwargs)\n\u001b[0;32m    654\u001b[0m     _pynative_executor\u001b[39m.\u001b[39mend_graph(\u001b[39mself\u001b[39m, output, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    655\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\miniconda3\\envs\\mindspore_2.0_0227\\lib\\site-packages\\mindspore\\nn\\cell.py:441\u001b[0m, in \u001b[0;36mCell._run_construct\u001b[1;34m(self, cast_inputs, kwargs)\u001b[0m\n\u001b[0;32m    439\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shard_fn(\u001b[39m*\u001b[39mcast_inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    440\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 441\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconstruct(\u001b[39m*\u001b[39;49mcast_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    442\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_enable_forward_hook:\n\u001b[0;32m    443\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_forward_hook(cast_inputs, output)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\miniconda3\\envs\\mindspore_2.0_0227\\lib\\site-packages\\mindspore\\nn\\layer\\transformer.py:409\u001b[0m, in \u001b[0;36mTransformerDecoderLayer.construct\u001b[1;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[0;32m    407\u001b[0m     x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ff_block(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm3(x))\n\u001b[0;32m    408\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 409\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm1(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sa_block(x, tgt_mask, tgt_key_padding_mask))\n\u001b[0;32m    410\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm2(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mha_block(x, memory, memory_mask, memory_key_padding_mask))\n\u001b[0;32m    411\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm3(x \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ff_block(x))\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\miniconda3\\envs\\mindspore_2.0_0227\\lib\\site-packages\\mindspore\\nn\\layer\\transformer.py:416\u001b[0m, in \u001b[0;36mTransformerDecoderLayer._sa_block\u001b[1;34m(self, x, attn_mask, key_padding_mask)\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_sa_block\u001b[39m(\u001b[39mself\u001b[39m, x, attn_mask, key_padding_mask):\n\u001b[1;32m--> 416\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself_attn(x, x, x,\n\u001b[0;32m    417\u001b[0m                        attn_mask\u001b[39m=\u001b[39;49mattn_mask,\n\u001b[0;32m    418\u001b[0m                        key_padding_mask\u001b[39m=\u001b[39;49mkey_padding_mask,\n\u001b[0;32m    419\u001b[0m                        need_weights\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)[\u001b[39m0\u001b[39m]\n\u001b[0;32m    420\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout1(x)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\miniconda3\\envs\\mindspore_2.0_0227\\lib\\site-packages\\mindspore\\nn\\layer\\transformer.py:177\u001b[0m, in \u001b[0;36mMultiheadAttention.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk_is_v \u001b[39m=\u001b[39m key \u001b[39mis\u001b[39;00m value\n\u001b[0;32m    176\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mq_is_k \u001b[39m=\u001b[39m query \u001b[39mis\u001b[39;00m key\n\u001b[1;32m--> 177\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\miniconda3\\envs\\mindspore_2.0_0227\\lib\\site-packages\\mindspore\\nn\\cell.py:653\u001b[0m, in \u001b[0;36mCell.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    651\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    652\u001b[0m     _pynative_executor\u001b[39m.\u001b[39mnew_graph(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 653\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_construct(args, kwargs)\n\u001b[0;32m    654\u001b[0m     _pynative_executor\u001b[39m.\u001b[39mend_graph(\u001b[39mself\u001b[39m, output, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    655\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\miniconda3\\envs\\mindspore_2.0_0227\\lib\\site-packages\\mindspore\\nn\\cell.py:441\u001b[0m, in \u001b[0;36mCell._run_construct\u001b[1;34m(self, cast_inputs, kwargs)\u001b[0m\n\u001b[0;32m    439\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shard_fn(\u001b[39m*\u001b[39mcast_inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    440\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 441\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconstruct(\u001b[39m*\u001b[39;49mcast_inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    442\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_enable_forward_hook:\n\u001b[0;32m    443\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_forward_hook(cast_inputs, output)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\miniconda3\\envs\\mindspore_2.0_0227\\lib\\site-packages\\mindspore\\nn\\layer\\transformer.py:212\u001b[0m, in \u001b[0;36mMultiheadAttention.construct\u001b[1;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights)\u001b[0m\n\u001b[0;32m    200\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m multi_head_attention_forward(\n\u001b[0;32m    201\u001b[0m         query, key, value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_dim, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads,\n\u001b[0;32m    202\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_weight, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_bias,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    209\u001b[0m         v_proj_weight\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mv_proj_weight, average_attn_weights\u001b[39m=\u001b[39maverage_attn_weights,\n\u001b[0;32m    210\u001b[0m         k_is_v\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mk_is_v, q_is_k\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mq_is_k)\n\u001b[0;32m    211\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 212\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m multi_head_attention_forward(\n\u001b[0;32m    213\u001b[0m         query, key, value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed_dim, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_heads,\n\u001b[0;32m    214\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49min_proj_weight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49min_proj_bias,\n\u001b[0;32m    215\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_k, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_v, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_zero_attn,\n\u001b[0;32m    216\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mbias,\n\u001b[0;32m    217\u001b[0m         training\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining,\n\u001b[0;32m    218\u001b[0m         key_padding_mask\u001b[39m=\u001b[39;49mkey_padding_mask,\n\u001b[0;32m    219\u001b[0m         attn_mask\u001b[39m=\u001b[39;49mattn_mask, average_attn_weights\u001b[39m=\u001b[39;49maverage_attn_weights,\n\u001b[0;32m    220\u001b[0m         k_is_v\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mk_is_v, q_is_k\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mq_is_k)\n\u001b[0;32m    222\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first \u001b[39mand\u001b[39;00m is_batched:\n\u001b[0;32m    223\u001b[0m     attn_output \u001b[39m=\u001b[39m attn_output\u001b[39m.\u001b[39mswapaxes(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\miniconda3\\envs\\mindspore_2.0_0227\\lib\\site-packages\\mindspore\\ops\\function\\nn_func.py:6046\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[1;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal, k_is_v, q_is_k)\u001b[0m\n\u001b[0;32m   6043\u001b[0m k \u001b[39m=\u001b[39m k\u001b[39m.\u001b[39mview(bsz, num_heads, src_len, head_dim)\n\u001b[0;32m   6044\u001b[0m v \u001b[39m=\u001b[39m v\u001b[39m.\u001b[39mview(bsz, num_heads, src_len, head_dim)\n\u001b[1;32m-> 6046\u001b[0m attn_output, attn_output_weights \u001b[39m=\u001b[39m _scaled_dot_product_attention(\n\u001b[0;32m   6047\u001b[0m     q, k, v, attn_mask, dropout_p, is_causal, training)\n\u001b[0;32m   6048\u001b[0m attn_output \u001b[39m=\u001b[39m attn_output\u001b[39m.\u001b[39mtranspose(\u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m)\u001b[39m.\u001b[39mview(bsz \u001b[39m*\u001b[39m tgt_len, embed_dim)\n\u001b[0;32m   6050\u001b[0m attn_output \u001b[39m=\u001b[39m linear(attn_output, out_proj_weight, out_proj_bias)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\miniconda3\\envs\\mindspore_2.0_0227\\lib\\site-packages\\mindspore\\ops\\function\\nn_func.py:5845\u001b[0m, in \u001b[0;36m_scaled_dot_product_attention\u001b[1;34m(query, key, value, attn_mask, dropout_p, is_causal, is_training)\u001b[0m\n\u001b[0;32m   5843\u001b[0m     attn, _ \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mdropout(attn, dropout_p)\n\u001b[0;32m   5844\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mattn type after dropout:\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mtype\u001b[39m(attn))\n\u001b[1;32m-> 5845\u001b[0m output \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39;49mmatmul(attn, value)\n\u001b[0;32m   5847\u001b[0m \u001b[39mreturn\u001b[39;00m (output, attn)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\miniconda3\\envs\\mindspore_2.0_0227\\lib\\site-packages\\mindspore\\ops\\function\\math_func.py:7908\u001b[0m, in \u001b[0;36mmatmul\u001b[1;34m(x1, x2)\u001b[0m\n\u001b[0;32m   7906\u001b[0m x2 \u001b[39m=\u001b[39m _expand(x2, ndim_aligned)\n\u001b[0;32m   7907\u001b[0m shape1_aligned, shape2_aligned \u001b[39m=\u001b[39m shape_op(x1), shape_op(x2)\n\u001b[1;32m-> 7908\u001b[0m x1 \u001b[39m=\u001b[39m _broadcast_to(x1, shape1_aligned[:\u001b[39m-\u001b[39;49m\u001b[39m2\u001b[39;49m], shape_backbone, ndim_aligned)\n\u001b[0;32m   7909\u001b[0m x2 \u001b[39m=\u001b[39m _broadcast_to(x2, shape2_aligned[:\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m], shape_backbone, ndim_aligned)\n\u001b[0;32m   7910\u001b[0m res \u001b[39m=\u001b[39m _batch_matmul(x1, x2)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\miniconda3\\envs\\mindspore_2.0_0227\\lib\\site-packages\\mindspore\\ops\\function\\math_func.py:7818\u001b[0m, in \u001b[0;36m_broadcast_to\u001b[1;34m(x, shape_cur, shape_to, ndim_to)\u001b[0m\n\u001b[0;32m   7816\u001b[0m size \u001b[39m=\u001b[39m tile_size_op(shape_cur, shape_to, ndim_to)\n\u001b[0;32m   7817\u001b[0m F\u001b[39m.\u001b[39mstop_gradient(size)\n\u001b[1;32m-> 7818\u001b[0m \u001b[39mreturn\u001b[39;00m tile_op(x, size)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\miniconda3\\envs\\mindspore_2.0_0227\\lib\\site-packages\\mindspore\\ops\\primitive.py:311\u001b[0m, in \u001b[0;36mPrimitive.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs):\n\u001b[1;32m--> 311\u001b[0m     should_elim, output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_elim(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    312\u001b[0m     \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m args:\n\u001b[0;32m    313\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(arg, Parameter) \u001b[39mand\u001b[39;00m arg\u001b[39m.\u001b[39mhas_init:\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\miniconda3\\envs\\mindspore_2.0_0227\\lib\\site-packages\\mindspore\\ops\\operations\\array_ops.py:2152\u001b[0m, in \u001b[0;36mTile.check_elim\u001b[1;34m(self, base_tensor, multiplier)\u001b[0m\n\u001b[0;32m   2148\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFor \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, the type of \u001b[39m\u001b[39m'\u001b[39m\u001b[39mmultiplier\u001b[39m\u001b[39m'\u001b[39m\u001b[39m must be tuple, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2149\u001b[0m                     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(multiplier)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   2151\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mall\u001b[39m(v \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m multiplier) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(base_tensor\u001b[39m.\u001b[39mshape) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(multiplier):\n\u001b[1;32m-> 2152\u001b[0m     ret \u001b[39m=\u001b[39m Identity()(base_tensor)\n\u001b[0;32m   2153\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, ret)\n\u001b[0;32m   2154\u001b[0m \u001b[39mreturn\u001b[39;00m (\u001b[39mFalse\u001b[39;00m, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\miniconda3\\envs\\mindspore_2.0_0227\\lib\\site-packages\\mindspore\\ops\\primitive.py:317\u001b[0m, in \u001b[0;36mPrimitive.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[39mif\u001b[39;00m should_elim:\n\u001b[0;32m    316\u001b[0m     \u001b[39mreturn\u001b[39;00m output\n\u001b[1;32m--> 317\u001b[0m \u001b[39mreturn\u001b[39;00m _run_op(\u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname, args)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\miniconda3\\envs\\mindspore_2.0_0227\\lib\\site-packages\\mindspore\\ops\\primitive.py:885\u001b[0m, in \u001b[0;36m_run_op\u001b[1;34m(obj, op_name, args)\u001b[0m\n\u001b[0;32m    883\u001b[0m     stub \u001b[39m=\u001b[39m _pynative_executor\u001b[39m.\u001b[39mrun_op_async(obj, args)\n\u001b[0;32m    884\u001b[0m     \u001b[39mreturn\u001b[39;00m _convert_stub(stub)\n\u001b[1;32m--> 885\u001b[0m \u001b[39mreturn\u001b[39;00m _run_op_sync(obj, op_name, args)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\miniconda3\\envs\\mindspore_2.0_0227\\lib\\site-packages\\mindspore\\common\\api.py:101\u001b[0m, in \u001b[0;36m_wrap_func.<locals>.wrapper\u001b[1;34m(*arg, **kwargs)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[39m@wraps\u001b[39m(fn)\n\u001b[0;32m    100\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39marg, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 101\u001b[0m     results \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49marg, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    102\u001b[0m     \u001b[39mreturn\u001b[39;00m _convert_python_data(results)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\miniconda3\\envs\\mindspore_2.0_0227\\lib\\site-packages\\mindspore\\ops\\primitive.py:891\u001b[0m, in \u001b[0;36m_run_op_sync\u001b[1;34m(obj, op_name, args)\u001b[0m\n\u001b[0;32m    888\u001b[0m \u001b[39m@_wrap_func\u001b[39m\n\u001b[0;32m    889\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_op_sync\u001b[39m(obj, op_name, args):\n\u001b[0;32m    890\u001b[0m     \u001b[39m\"\"\"Single op execution function in synchronous mode.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 891\u001b[0m     output \u001b[39m=\u001b[39m _pynative_executor\u001b[39m.\u001b[39;49mreal_run_op(obj, op_name, args)\n\u001b[0;32m    892\u001b[0m     \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\miniconda3\\envs\\mindspore_2.0_0227\\lib\\site-packages\\mindspore\\common\\api.py:1039\u001b[0m, in \u001b[0;36m_PyNativeExecutor.real_run_op\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1029\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreal_run_op\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs):\n\u001b[0;32m   1030\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1031\u001b[0m \u001b[39m    Run single op.\u001b[39;00m\n\u001b[0;32m   1032\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1037\u001b[0m \u001b[39m        Tensor, result of run op.\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1039\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_executor\u001b[39m.\u001b[39;49mreal_run_op(\u001b[39m*\u001b[39;49margs)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from mindspore.ops.function.nn_func import multi_head_attention_forward\n",
    "\n",
    "net_work = nn.Transformer()\n",
    "\n",
    "src = Tensor(np.random.rand(128, 32, 512), mindspore.float32)\n",
    "trg = Tensor(np.random.rand(128, 32, 512), mindspore.float32)\n",
    "\n",
    "def forward_fn(src, trg):\n",
    "    out = net_work(src, trg)\n",
    "    loss = loss_fn(out, trg)\n",
    "    return loss\n",
    "\n",
    "optimizer = nn.Adam(net_work.trainable_params(), learning_rate=0.0001)\n",
    "grad_fn = mindspore.value_and_grad(forward_fn, None, optimizer.parameters)\n",
    "\n",
    "def train_step(src, trg):\n",
    "    loss, grads = grad_fn(src, trg)\n",
    "    optimizer(grads)\n",
    "    return loss\n",
    "\n",
    "net_work.set_train(True)   \n",
    "train_step(src, trg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_work = nn.Transformer()\n",
    "\n",
    "src = Tensor(np.random.rand(128, 32, 512), mindspore.float32)\n",
    "trg = Tensor(np.random.rand(128, 32, 512), mindspore.float32)\n",
    "\n",
    "def forward_fn(src, trg):\n",
    "    out = net_work(src, trg)\n",
    "    loss = loss_fn(out, trg)\n",
    "    return loss\n",
    "\n",
    "optimizer = nn.Adam(net_work.trainable_params(), learning_rate=0.0001)\n",
    "grad_fn = mindspore.value_and_grad(forward_fn, None, optimizer.parameters)\n",
    "\n",
    "def train_step(src, trg):\n",
    "    loss, grads = grad_fn(src, trg)\n",
    "    optimizer(grads)\n",
    "\n",
    "# net_work.set_train(True)   \n",
    "train_step(src, trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Tensor(shape=[2, 1], dtype=Int32, value=\n",
       " [[1],\n",
       "  [4]]),\n",
       " Tensor(shape=[2, 1], dtype=Int32, value=\n",
       " [[2],\n",
       "  [5]]),\n",
       " Tensor(shape=[2, 1], dtype=Int32, value=\n",
       " [[3],\n",
       "  [6]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mindspore\n",
    "from mindspore import Tensor \n",
    "\n",
    "t_test = Tensor([[1, 2, 3],[4, 5, 6]], mindspore.int32)\n",
    "print(t_test.shape)\n",
    "t_test.tensor_split(3, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindspore.ops import functional as F\n",
    "F.cross_entropy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d735f6cc625ca8b095620eeb46a50be5e34ded063dbe74c6d5dc8e1ec88bb29c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
